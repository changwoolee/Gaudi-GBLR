# @package _global_
defaults:
  - /experiment/imagenet/vit/vit-b.yaml
  - override /model/vitmlp_cfg: gblr

model:
  drop_path_rate: 0.0
  drop_rate: 0.0
  mlp_cfg:
    linear1_cfg:
      rank_per_component: 1
      total_rank_ratio: 1.0
      fixed_width: false
      fixed_location: false
      min_widths: [0.0, 0.0]
      max_widths: [1.0, 1.0]
      width_init: 'splr'
      compute_mode: "dense"
      location_init: 0. 
      width_learning_rate: 0.0005
      width_weight_decay: 0.0
      location_learning_rate: ${.width_learning_rate}
      beta: 2.0
      adam_betas: [0.0, 0.999]
      custom_grad: false
  attnlinear_cfg: ${model.mlp_cfg.linear1_cfg}

callbacks:
  sigma_annealing:
    _target_: src.callbacks.fm_sigma_annealing.SigmaAnnealing
    sigma_init: 1.0
    sigma_final: 100.0
    start_epoch: 5
    end_epoch: 300
  width_monitor:
    _target_: src.callbacks.width_monitor.WidthMonitor
  flop_count:
    _target_: src.callbacks.flop_count.FlopCount 
    profilers: ["fvcore"] 
    input_size: [3,224,224] 
    sinc_gaussian: true
    baseline_complexity: 1.72e10
  shrink:
    _target_: src.callbacks.shrink.AdaptiveSoftshrink
    thres: 0.04
    target_width: 0.13
    init_thres: ${.thres}
    start_epoch: ${train.scheduler.warmup_t}
    end_epoch: ${.start_epoch}

